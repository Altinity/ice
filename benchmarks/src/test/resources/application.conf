# ICE REST Catalog Benchmark Configuration
# 
# This configuration file defines parameters for load testing the ICE REST catalog.
# It follows the same structure as the Polaris benchmarking framework.

# HTTP connection settings
http {
  # Base URL of the ICE REST catalog
  base-url = "http://localhost:5000"
  base-url = ${?ICE_CATALOG_URL}
  
  # Connection timeout in milliseconds
  connect-timeout = 30000
  
  # Request timeout in milliseconds  
  request-timeout = 60000
}

# Authentication settings
auth {
  # Bearer token for authentication
  # Set this via environment variable: export ICE_BEARER_TOKEN="your-token"
  # Or set directly in this file: bearer-token = "your-token-here"
  bearer-token = "foo"
  bearer-token = ${?ICE_BEARER_TOKEN}
}

# Test dataset configuration
dataset {
  # Catalog configuration
  catalog-name = "test-catalog"
  
  # Tree dataset structure
  tree {
    # Number of catalogs to create (for multi-catalog tests)
    num-catalogs = 1
    
    # Namespace hierarchy configuration
    # Width: number of child namespaces per parent
    namespace-width = 2
    # Depth: levels of namespace nesting
    namespace-depth = 3
    
    # Tables and views per namespace
    tables-per-namespace = 5
    views-per-namespace = 2
    
    # Metadata properties
    namespace-properties = 10
    table-properties = 20
    view-properties = 15
    
    # Schema configuration
    columns-per-table = 50
    columns-per-view = 30
    
    # Default base location for tables
    default-base-location = "s3://test-warehouse/"
    default-base-location = ${?ICE_BASE_LOCATION}
  }
}

# Workload configurations
workload {
  # Pure write workload - creates namespaces, tables, and views
  create-tree-dataset {
    # Concurrency for namespace creation
    namespace-concurrency = 20
    # Concurrency for table creation
    table-concurrency = 40
    # Concurrency for view creation
    view-concurrency = 40
  }
  
  # Mixed read/write workload - 90% reads, 10% writes
  read-update-tree-dataset {
    # Ratio of read operations (0.0 to 1.0)
    read-write-ratio = 0.9
    # Target throughput (operations per second)
    throughput = 150
    # Duration of the benchmark in minutes
    duration-in-minutes = 10
  }
  
  # Read-heavy workload - 100% reads
  read-only-workload {
    # Target throughput (operations per second)
    throughput = 500
    # Duration of the benchmark in minutes
    duration-in-minutes = 5
  }
  
  # Write-heavy workload - table updates
  write-heavy-workload {
    # Concurrency for table updates
    update-concurrency = 50
    # Number of updates per table
    updates-per-table = 10
  }
}

